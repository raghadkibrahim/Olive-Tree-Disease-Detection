{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d398371-c362-418b-a47e-68947e77d719",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b352be-2d10-4e94-984e-ca87bc06c771",
   "metadata": {
    "tags": []
   },
   "source": [
    "<i><p style=\"border-width:2px; border-style:solid; border-color:#808080; padding: 0.5em;text-align:left;\">PART I: Project Overview</p></i>\n",
    "\n",
    "> **1. [Introduction](#intro)**\n",
    "\t> > 1.1. [Literature Review](#1.1)\n",
    ">\n",
    "<i><p style=\"border-width:2px; border-style:solid; border-color:#808080; padding: 0.5em;text-align:left;\">PART II: Data Analysis</p></i>\n",
    "> \n",
    "> **2. [Methodology](#methodology)**\n",
    "\t> > 2.1 [Approach](#2.1)   \n",
    "\t> > 2.2 [Dataset](#2.2)     \n",
    "\t> > 2.3 [Dependencies](#2.3)   \n",
    "\t> > 2.4 [Getting Started](#2.4)\n",
    ">\n",
    "> **3. [Data Preprocessing](#preprocessing)**\n",
    "\t> > 3.1 [A First Look At The Data](#3.1)  \n",
    "\t> > 3.2 [Identifying Image Imbalance](#3.2)  \n",
    "\t> > 3.3 [Plotting Image Size](#3.3)     \n",
    ">\n",
    "> **4. [Exploratory Data Analysis](#eda)**   \n",
    "> > 4.1. [Orientation](#4.1)  \n",
    "> > 4.2. [RGB Channels](#4.2)  \n",
    ">\n",
    "> **5. [Modeling and Evaluation](#model_eval)**\n",
    ">\n",
    "<i><p style=\"border-width:2px; border-style:solid; border-color:#808080; padding: 0.5em;text-align:left;\">PART III: Findings</p></i>\n",
    "> \n",
    "> **6. [Discussion](#discussion)**  \n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8732a29-3840-4911-a6f2-a0b1e6c07169",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## IMPORT LIBRARIES ##\n",
    "\n",
    "import numpy as np #numpy for \n",
    "\n",
    "import pandas as pd # pandas\n",
    "\n",
    "from matplotlib import pyplot as plt # matplot library\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6daa6f2d-1813-42a8-8de6-3a50bd1c4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT LIBRARIES ##\n",
    "\n",
    "import os  \n",
    "from matplotlib import image as mpimg\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "from skimage import io, img_as_float, img_as_ubyte\n",
    "from skimage.io import imread, imshow\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48aaad7-b28e-49a2-bd58-a6f2b83dc2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the image directories ##\n",
    "\n",
    "dir = 'dataset' # paste your folder directory\n",
    "\n",
    "# returns a list containing the names of the images in the `healthy` folder\n",
    "training_healthy_data= os.listdir(dir + '/training/healthy') # training dataset\n",
    "testing_healthy_data = os.listdir(dir + '/training/healthy') # testing dataset\n",
    "\n",
    "# returns a list containing the names of the images in the `aculus olearius` folder\n",
    "training_aculus_data= os.listdir(dir + '/training/aculus_olearius') # training dataset \n",
    "testing_aculus_data = os.listdir(dir + '/training/aculus_olearius') # testing dataset\n",
    "\n",
    "# returns a list containing the names of the images in the `peacock spot` folder\n",
    "training_peacock_data= os.listdir(dir + '/training/peacock_spot') # training dataset \n",
    "testing_peacock_data = os.listdir(dir + '/training/peacock_spot/') # testing dataset\n",
    "\n",
    "#all_data = [healthy_data, aculus_olearius_data, peacock_disease_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01011480-1c1b-4b67-a4f2-b7c37b736f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = {\n",
    "    'Healthy Leaves': os.path.join(dir, 'training/healthy'), # Path to the directory containing the Healthy Leaves dataset\n",
    "    'Aculus Olearius Leaves': os.path.join(dir, 'training/aculus_olearius'), # Path to the directory containing images with Aculus Olearius Leaves\n",
    "    'Peacock Spot Leaves': os.path.join(dir, 'training/peacock_spot') # Path to the directory containing images with Peacock Spot Leaves\n",
    "}\n",
    "\n",
    "testing_dir = {\n",
    "    'Healthy Leaves': os.path.join(dir, 'testing/healthy'), # Path to the directory containing the Healthy Leaves dataset\n",
    "    'Aculus Olearius Leaves': os.path.join(dir, 'testing/aculus_olearius'), # Path to the directory containing images with Aculus Olearius Leaves\n",
    "    'Peacock Spot Leaves': os.path.join(dir, 'testing/peacock_spot') # Path to the directory containing images with Peacock Spot Leaves\n",
    "}\n",
    "\n",
    "training_data = {\n",
    "    'Healthy Leaves': training_healthy_data, # Path to the directory containing the Healthy Leaves dataset\n",
    "    'Aculus Olearius Leaves': training_aculus_data, # Path to the directory containing images with Aculus Olearius Leaves\n",
    "    'Peacock Disease Leaves': training_peacock_data # Path to the directory containing images with Peacock Spot Leaves\n",
    "}\n",
    "\n",
    "testing_data = {\n",
    "    'Healthy Leaves': testing_healthy_data, # Path to the directory containing the Healthy Leaves dataset\n",
    "    'Aculus Olearius Leaves': testing_aculus_data, # Path to the directory containing images with Aculus Olearius Leaves\n",
    "    'Peacock Disease Leaves': testing_peacock_data # Path to the directory containing images with Peacock Spot Leaves\n",
    "}\n",
    "##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e6afa-0ee3-463f-bca6-dcd0649b7a3e",
   "metadata": {},
   "source": [
    "Now that the dataset has been successfully loaded from the corresponding directories, we can proceed with the preprocessing stage. \n",
    "<br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "893bf428-aad4-4881-9e85-ce5c94ddd4c5",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "*PART II: Data Analysis* \n",
    "\n",
    "<a id='model_eval'></a>\n",
    "## Baseline Models and Evaluation\n",
    "\n",
    "A baseline model is developed here to set a benchmark for classification performance. The evaluation framework focused on accuracy, precision, recall, and F1 score metrics to assess the model's effectiveness in correctly classifying the leaf images. Initial results indicated promising classification capabilities, with specific attention paid to minimizing false negatives to avoid missed detections of diseased or infested leaves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe85eb5-bb20-4dad-901c-5486377c1b54",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f9f8f-7e16-4cd3-8eea-ab532afadc48",
   "metadata": {},
   "source": [
    "(use more words to explain outline of what I'm doing)\n",
    "The first model we will build is a Logistic Regression model as seen below: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12881bc9-33fd-4ac5-a1b3-51c000e515c5",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4411c-003e-4eff-9c87-4168e69e9bfe",
   "metadata": {},
   "source": [
    "For a Logistic Regression model I will be importing the following libraries from `scikit-learn` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d34278c6-a150-426d-a537-180ac2d7cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4fe24b-0d55-41bf-9894-ca9012760b95",
   "metadata": {},
   "source": [
    "#### Instantiate and Fit the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db86681-880f-4b4f-a920-4c26269c4bab",
   "metadata": {},
   "source": [
    "STEP 1:\n",
    "Iterate through the different classes to :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c872d3ba-f37b-425d-8dfa-5b56e86177ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on:  B-624.jpg807_144239.jpg\r"
     ]
    }
   ],
   "source": [
    "# HEALTHY \n",
    "# create empty list for the concatenated counts - big list\n",
    "\n",
    "big_list = []\n",
    "\n",
    "for i in training_healthy_data:\n",
    "    print(\"Working on: \", i, end=\"\\r\")\n",
    "    try:\n",
    "        img = mpimg.imread(dir + '/healthy/' + i)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # create empty list for the 3 counts\n",
    "    img_rgb = []\n",
    "    channels = [0,1,2]\n",
    "    \n",
    "    # loop through the 3 color channels\n",
    "    for  channel in channels:\n",
    "        \n",
    "        # get histogram and counts for the channel\n",
    "        counts, bins = np.histogram(img[:,:,channel].ravel(), bins = np.linspace(0, 255, 51))\n",
    "        \n",
    "        # put counts into the list\n",
    "        img_rgb.append(counts)\n",
    "        \n",
    "        # concat the 3 counts into a single array of length 150\n",
    "        large_counts = np.concatenate(img_rgb)\n",
    "    \n",
    "    # save the large array into the big list\n",
    "    big_list.append(large_counts)\n",
    "    \n",
    "# we get a large list with as many arrays as images, each array is length 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "840a55e8-201d-4c57-ba98-56a735556b39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aculus_olearius_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ACULUS OLEARIUS\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# create empty list for the concatenated counts - big list\u001b[39;00m\n\u001b[1;32m      4\u001b[0m big_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m aculus_olearius_data:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorking on: \u001b[39m\u001b[38;5;124m\"\u001b[39m, i, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aculus_olearius_data' is not defined"
     ]
    }
   ],
   "source": [
    "# ACULUS OLEARIUS\n",
    "# create empty list for the concatenated counts - big list\n",
    "\n",
    "big_list = []\n",
    "\n",
    "for i in training_aculus_data:\n",
    "    print(\"Working on: \", i, end=\"\\r\")\n",
    "    try:\n",
    "        img = mpimg.imread(dir + '/training/aculus_olearius/' + i)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # create empty list for the 3 counts\n",
    "    img_rgb = []\n",
    "    channels = [0,1,2]\n",
    "    # loop through the 3 color channels\n",
    "    for  channel in channels:\n",
    "        # get histogram and counts for the channel\n",
    "        counts, bins = np.histogram(img[:,:,channel].ravel(), bins=np.linspace(0, 255, 51))\n",
    "        \n",
    "        # put counts into the list\n",
    "        img_rgb.append(counts)\n",
    "        \n",
    "        # concat the 3 counts into a single array of length 150\n",
    "        large_counts = np.concatenate(img_rgb)\n",
    "        \n",
    "    # save the large array into the big list\n",
    "    big_list.append(large_counts)\n",
    "    \n",
    "# we get a large list with as many arrays as images, each array is length 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea39217-7fba-45ec-a126-e626da152b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on:  IMG_20190806_143133.jpg\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# loop through the 3 color channels\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m  channel \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[1;32m     18\u001b[0m     \n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# get histogram and counts for the channel\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     counts, bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(img[:,:,channel]\u001b[38;5;241m.\u001b[39mravel(), bins\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m51\u001b[39m))\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# put counts into the list\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     img_rgb\u001b[38;5;241m.\u001b[39mappend(counts)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# PEACOCK DISEASE \n",
    "# create empty list for the concatenated counts - big list\n",
    "\n",
    "big_list = []\n",
    "\n",
    "for i in training_peacock_data:\n",
    "    print(\"Working on: \", i, end = \"\\r\")\n",
    "    try:\n",
    "        img = mpimg.imread(dir + '/training/peacock_spot/' + i)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # create empty list for the 3 counts\n",
    "    img_rgb = []\n",
    "    channels = [0,1,2]\n",
    "    # loop through the 3 color channels\n",
    "    for  channel in channels:\n",
    "        \n",
    "        # get histogram and counts for the channel\n",
    "        counts, bins = np.histogram(img[:,:,channel].ravel(), bins=np.linspace(0, 255, 51))\n",
    "        \n",
    "        # put counts into the list\n",
    "        img_rgb.append(counts)\n",
    "        \n",
    "        # concat the 3 counts into a single array of length 150\n",
    "        large_counts = np.concatenate(img_rgb)\n",
    "        \n",
    "    # save the large array into the big list\n",
    "    big_list.append(large_counts)\n",
    "    \n",
    "# we get a large list with as many arrays as images, each array is length 150\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0cf779-09f9-4e2d-b335-9eb1a4503a13",
   "metadata": {},
   "source": [
    "STEP 2: Now to join the large array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9026c487-d9c4-4b99-b7b0-fe157f761d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN THE LARGE ARRAY\n",
    "\n",
    "healthy_hist = np.stack(big_list)\n",
    "healthy_label = np.full(healthy_hist.shape[0], 0)\n",
    "\n",
    "aculus_olearius_hist = np.stack(big_list)\n",
    "aculus_olearius_label = np.full(aculus_olearius_hist.shape[0], 1)\n",
    "\n",
    "peacock_disease_hist = np.stack(big_list)\n",
    "peacock_disease_label = np.full(peacock_disease_hist.shape[0], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35f130-2aea-442c-ba2f-1bf080d707df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SANITY CHECK\n",
    "\n",
    "display(healthy_label.shape, aculus_olearius_hist.shape, peacock_disease_hist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f1a7d-4bbb-4758-a99e-a23ac354a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate \n",
    "\n",
    "x = np.concatenate([healthy_hist, aculus_olearius_hist, peacock_disease_hist])\n",
    "y = np.concatenate([healthy_label,aculus_olearius_label,peacock_disease_label])\n",
    "\n",
    "\n",
    "# SANITY CHECK\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c0716-3efc-4c4d-baa9-88d49f3ec961",
   "metadata": {},
   "source": [
    "STEP 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c71f6af-2a5d-4a97-933a-b8a593700a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4846b4ee-9c8d-4080-975c-7d7ed7662699",
   "metadata": {},
   "source": [
    "talk about .. idk something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6ddd9e-b859-4921-88b5-d836cf44d004",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90278436-9b86-48a3-9238-534a89e7f191",
   "metadata": {},
   "source": [
    "For further evaluation I will also compute the precision, recall, and f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac09c4-b754-4f73-8b4f-4d002c37846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "\n",
    "report_initial = classification_report(y, model.predict(x))\n",
    "print(report_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be2059e-6061-4a36-8292-d05487108ab9",
   "metadata": {},
   "source": [
    "This model achieves an accuracy of 76.6%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3932de-0fb8-4ec6-bfc8-ddf246605544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(model, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a35c4ad-37df-484a-8d57-352b724aaafa",
   "metadata": {},
   "source": [
    "The confusion matrix shows us how many images from each classes were predicted correctly or incorrectly. We can see that this model performed pretty well in classifying the first and third classes but not as well in classifying leaves with aculus olearius which it mostly classified incorrectly as being healthy. This is expected because as we saw in the pre-processing stage the leaves with aculus olearius look a lot like healthy leaves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690cbff9-50c6-4292-b734-977d606fe244",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e07a9de2-4be0-4f23-8b60-6ff09bdaf8d3",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "*PART III: Findings* \n",
    "\n",
    "<a id='results'></a>\n",
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b2d4a8-bcc5-49c6-9bf1-1f744c140649",
   "metadata": {},
   "source": [
    "<a id='discussion'></a>\n",
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07183bf5-31e8-4386-be51-d99665aa3647",
   "metadata": {},
   "source": [
    "The project's findings showcase the potential of image processing and machine learning in transforming agricultural practices through enhanced disease detection. Future work will focus on improving model accuracy and enhancing the model's classification capabilities by exploring transfer learning and deep learning techniques.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
